# Llama-3.1-8B on HF InferenceClient
#python sample.py --model meta-llama/Llama-3.1-8B-Instruct --prompt="Who wrote the book '1984'?" 
#python sample.py --model meta-llama/Llama-3.1-8B-Instruct --prompt="Who wrote the book '1984'?" --no-stream

# Deepseek-R1-8B on Ollama 
#python sample.py --model deepseek-r1:8b --prompt="Who wrote the book '1984'?"
#python sample.py --model deepseek-r1:8b --prompt="Who wrote the book '1984'?" --no-stream

